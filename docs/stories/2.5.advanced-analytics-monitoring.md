# Story 2.5: Advanced Analytics & Monitoring

## Status
Draft

## Story
**As a** content strategist,  
**I want** advanced analytics on query patterns, knowledge gaps, and content optimization insights,  
**so that** I can make data-driven decisions about knowledge base improvement and content strategy.

## Acceptance Criteria
1. **Query Pattern Analysis**: Implement clustering and categorization of queries to identify common themes and usage patterns
2. **Knowledge Gap Detection**: Analyze failed queries and low-satisfaction responses to identify content gaps and improvement opportunities
3. **Content Utilization Insights**: Provide analytics on document usage patterns, underutilized content, and optimization recommendations
4. **Predictive Analytics**: Basic forecasting for query volume trends and performance capacity planning
5. **Advanced Dashboard Features**: Extend existing dashboard with additional charts and insights for strategic decision-making
6. **Export Capabilities**: Allow data export for external analysis and reporting to stakeholders

## Tasks / Subtasks
- [ ] Implement query pattern analysis (AC: 1)
  - [ ] Create `QueryPatternAnalyzer` class in `mcp_rag_playground/analytics/pattern_analyzer.py`
  - [ ] Implement text clustering using simple keyword extraction and frequency analysis
  - [ ] Create query categorization based on common patterns (questions, commands, searches)
  - [ ] Add trend analysis for query patterns over time
  - [ ] Generate insights about most common query types and topics
- [ ] Build knowledge gap detection system (AC: 2)
  - [ ] Create `KnowledgeGapDetector` class in `mcp_rag_playground/analytics/gap_detector.py`
  - [ ] Analyze queries with zero results or low similarity scores
  - [ ] Identify patterns in low-rated user responses (1-2 star ratings)
  - [ ] Generate gap reports with suggested content topics
  - [ ] Track gap resolution progress over time
- [ ] Develop content utilization analytics (AC: 3)
  - [ ] Create `ContentAnalyzer` class in `mcp_rag_playground/analytics/content_analyzer.py`
  - [ ] Analyze document access frequency and recency patterns
  - [ ] Identify underutilized documents and high-value content
  - [ ] Generate content optimization recommendations
  - [ ] Create content performance scoring based on user satisfaction and usage
- [ ] Add basic predictive analytics (AC: 4)
  - [ ] Create `PredictiveAnalyzer` class in `mcp_rag_playground/analytics/predictive_analyzer.py`
  - [ ] Implement simple trend forecasting for query volumes
  - [ ] Add capacity planning insights based on response time trends
  - [ ] Generate alerts for unusual pattern deviations
  - [ ] Create simple seasonality detection for usage patterns
- [ ] Extend dashboard with advanced features (AC: 5)
  - [ ] Add new API endpoints in `mcp_rag_playground/api/dashboard.py` for advanced analytics
  - [ ] Create pattern analysis visualization in dashboard frontend
  - [ ] Add knowledge gap identification charts and tables
  - [ ] Implement content utilization heatmaps and recommendations
  - [ ] Add predictive trend charts with forecasting
- [ ] Implement data export capabilities (AC: 6)
  - [ ] Create export API endpoints for CSV, JSON formats
  - [ ] Add export functionality for analytics reports and insights
  - [ ] Implement configurable date ranges and data filtering for exports
  - [ ] Create downloadable reports for stakeholder sharing
  - [ ] Add export scheduling for automated reporting
- [ ] Unit testing for advanced analytics (AC: 1-6)
  - [ ] Test query pattern analysis with sample data sets
  - [ ] Test knowledge gap detection with known problematic queries
  - [ ] Test content utilization calculations with document access data
  - [ ] Test predictive analytics algorithms with historical data
  - [ ] Test new dashboard features and API endpoints
  - [ ] Test export functionality and data format validation

## Dev Notes

### Previous Story Insights
This story represents the final enhancement layer for Epic 2, building upon the complete analytics infrastructure (Stories 2.1-2.4) to provide strategic insights and advanced monitoring capabilities. The foundation of analytics service, MCP integration, backend APIs, and dashboard interface enables this story to focus on sophisticated analysis algorithms and business intelligence features.

### Dependencies
- **Stories 2.1-2.4**: Complete analytics foundation required
- **Established Analytics Database**: Historical data needed for pattern analysis
- **Dashboard Infrastructure**: Frontend components for advanced visualization

### Advanced Analytics Specifications

**Query Pattern Analysis** (Required Implementation):
```python
class QueryPatternAnalyzer:
    def __init__(self, analytics_service: AnalyticsService):
        self.analytics_service = analytics_service
        
    def analyze_query_patterns(self, days: int = 30) -> Dict:
        """Analyze query patterns and categorize common themes"""
        queries = self.analytics_service.get_queries_by_date_range(days)
        
        # Simple pattern analysis
        patterns = {
            'question_queries': self._extract_questions(queries),
            'command_queries': self._extract_commands(queries),
            'search_queries': self._extract_searches(queries),
            'common_keywords': self._extract_keywords(queries),
            'temporal_patterns': self._analyze_temporal_patterns(queries)
        }
        
        return patterns
        
    def _extract_questions(self, queries: List[str]) -> List[Dict]:
        """Identify question-based queries"""
        question_words = ['what', 'how', 'why', 'when', 'where', 'who']
        questions = []
        
        for query in queries:
            if any(word in query.lower() for word in question_words):
                questions.append({
                    'query': query,
                    'question_type': self._classify_question_type(query),
                    'frequency': queries.count(query)
                })
                
        return sorted(questions, key=lambda x: x['frequency'], reverse=True)
        
    def _classify_question_type(self, query: str) -> str:
        """Classify question type for better categorization"""
        query_lower = query.lower()
        if 'how' in query_lower:
            return 'procedural'
        elif 'what' in query_lower:
            return 'definitional'
        elif 'why' in query_lower:
            return 'explanatory'
        else:
            return 'general'
```

**Knowledge Gap Detection** (Required Implementation):
```python
class KnowledgeGapDetector:
    def __init__(self, analytics_service: AnalyticsService):
        self.analytics_service = analytics_service
        
    def detect_knowledge_gaps(self, days: int = 30) -> Dict:
        """Identify content gaps based on failed queries and low satisfaction"""
        failed_queries = self.analytics_service.get_failed_queries(days)
        low_rated_queries = self.analytics_service.get_low_rated_queries(days, max_rating=2)
        
        gaps = {
            'zero_result_queries': self._analyze_zero_results(failed_queries),
            'low_satisfaction_topics': self._analyze_low_satisfaction(low_rated_queries),
            'missing_content_suggestions': self._generate_content_suggestions(failed_queries),
            'gap_severity_score': self._calculate_gap_severity(failed_queries, low_rated_queries)
        }
        
        return gaps
        
    def _analyze_zero_results(self, failed_queries: List[Dict]) -> List[Dict]:
        """Analyze queries that returned zero results"""
        return [
            {
                'query': query['query_text'],
                'frequency': query['frequency'],
                'last_attempted': query['last_timestamp'],
                'suggested_topics': self._extract_topics(query['query_text'])
            }
            for query in failed_queries
            if query['result_count'] == 0
        ]
        
    def _generate_content_suggestions(self, failed_queries: List[Dict]) -> List[str]:
        """Generate content creation suggestions based on failed queries"""
        topics = []
        for query in failed_queries:
            extracted_topics = self._extract_topics(query['query_text'])
            topics.extend(extracted_topics)
            
        # Return most frequent topics as content suggestions
        topic_counts = Counter(topics)
        return [topic for topic, count in topic_counts.most_common(10)]
```

**Content Utilization Analytics** (Required Implementation):
```python
class ContentAnalyzer:
    def __init__(self, analytics_service: AnalyticsService):
        self.analytics_service = analytics_service
        
    def analyze_content_utilization(self, days: int = 30) -> Dict:
        """Analyze how content is being used and identify optimization opportunities"""
        document_stats = self.analytics_service.get_document_usage_stats(days)
        
        analysis = {
            'high_value_documents': self._identify_high_value_content(document_stats),
            'underutilized_documents': self._identify_underutilized_content(document_stats),
            'content_performance_scores': self._calculate_content_scores(document_stats),
            'optimization_recommendations': self._generate_optimization_recommendations(document_stats)
        }
        
        return analysis
        
    def _identify_high_value_content(self, document_stats: List[Dict]) -> List[Dict]:
        """Identify documents with high usage and satisfaction"""
        return [
            doc for doc in document_stats
            if doc['access_count'] > self._get_access_threshold() and
               doc['avg_satisfaction'] > 4.0
        ]
        
    def _calculate_content_scores(self, document_stats: List[Dict]) -> Dict[str, float]:
        """Calculate performance scores for all documents"""
        scores = {}
        for doc in document_stats:
            # Weighted score based on usage, satisfaction, and recency
            usage_score = min(doc['access_count'] / 100, 1.0)  # Normalize to 0-1
            satisfaction_score = (doc['avg_satisfaction'] - 1) / 4  # Convert 1-5 to 0-1
            recency_score = self._calculate_recency_score(doc['last_accessed'])
            
            scores[doc['document_id']] = (
                usage_score * 0.4 + 
                satisfaction_score * 0.4 + 
                recency_score * 0.2
            )
            
        return scores
```

### API Extensions

**Advanced Analytics Endpoints** (Required Implementation):
```python
# Add to mcp_rag_playground/api/dashboard.py

@dashboard_router.get("/api/advanced/query-patterns")
async def get_query_patterns(days: int = 30) -> Dict:
    """Get query pattern analysis for strategic insights"""
    pattern_analyzer = container.query_pattern_analyzer()
    return pattern_analyzer.analyze_query_patterns(days)

@dashboard_router.get("/api/advanced/knowledge-gaps")
async def get_knowledge_gaps(days: int = 30) -> Dict:
    """Get knowledge gap analysis and content suggestions"""
    gap_detector = container.knowledge_gap_detector()
    return gap_detector.detect_knowledge_gaps(days)

@dashboard_router.get("/api/advanced/content-utilization")
async def get_content_utilization(days: int = 30) -> Dict:
    """Get content utilization analysis and optimization recommendations"""
    content_analyzer = container.content_analyzer()
    return content_analyzer.analyze_content_utilization(days)

@dashboard_router.get("/api/export/analytics-report")
async def export_analytics_report(
    format: str = "json", 
    days: int = 30,
    include_patterns: bool = True,
    include_gaps: bool = True,
    include_content: bool = True
) -> Dict:
    """Export comprehensive analytics report"""
    report = {}
    
    if include_patterns:
        report['query_patterns'] = await get_query_patterns(days)
    if include_gaps:
        report['knowledge_gaps'] = await get_knowledge_gaps(days)
    if include_content:
        report['content_utilization'] = await get_content_utilization(days)
        
    report['generated_at'] = datetime.now().isoformat()
    report['time_period_days'] = days
    
    return report
```

### Dashboard Extensions

**Advanced Visualization Components** (Required Implementation):
```javascript
// Add to dashboard.js

class AdvancedDashboard extends DashboardManager {
    async loadAdvancedAnalytics() {
        try {
            const [patterns, gaps, content] = await Promise.all([
                fetch('/dashboard/api/advanced/query-patterns').then(r => r.json()),
                fetch('/dashboard/api/advanced/knowledge-gaps').then(r => r.json()),
                fetch('/dashboard/api/advanced/content-utilization').then(r => r.json())
            ]);
            
            this.createQueryPatternsChart(patterns);
            this.createKnowledgeGapsTable(gaps);
            this.createContentUtilizationHeatmap(content);
        } catch (error) {
            console.error('Failed to load advanced analytics:', error);
        }
    }
    
    createQueryPatternsChart(patterns) {
        const ctx = document.getElementById('query-patterns-chart').getContext('2d');
        
        new Chart(ctx, {
            type: 'doughnut',
            data: {
                labels: ['Questions', 'Commands', 'Searches', 'Other'],
                datasets: [{
                    data: [
                        patterns.question_queries.length,
                        patterns.command_queries.length,
                        patterns.search_queries.length,
                        patterns.other_queries?.length || 0
                    ],
                    backgroundColor: [
                        'rgba(54, 162, 235, 0.8)',
                        'rgba(255, 99, 132, 0.8)',
                        'rgba(255, 205, 86, 0.8)',
                        'rgba(75, 192, 192, 0.8)'
                    ]
                }]
            },
            options: {
                responsive: true,
                plugins: {
                    title: {
                        display: true,
                        text: 'Query Type Distribution'
                    },
                    legend: {
                        position: 'bottom'
                    }
                }
            }
        });
    }
    
    async exportAnalyticsReport() {
        try {
            const response = await fetch('/dashboard/api/export/analytics-report?format=json&days=30');
            const report = await response.json();
            
            const blob = new Blob([JSON.stringify(report, null, 2)], { type: 'application/json' });
            const url = URL.createObjectURL(blob);
            
            const a = document.createElement('a');
            a.href = url;
            a.download = `kb-analytics-report-${new Date().toISOString().split('T')[0]}.json`;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
        } catch (error) {
            console.error('Failed to export report:', error);
            alert('Failed to export analytics report. Please try again.');
        }
    }
}
```

### File Locations

**Files to Create**:
- `mcp_rag_playground/analytics/pattern_analyzer.py` - Query pattern analysis
- `mcp_rag_playground/analytics/gap_detector.py` - Knowledge gap detection
- `mcp_rag_playground/analytics/content_analyzer.py` - Content utilization analysis
- `mcp_rag_playground/analytics/predictive_analyzer.py` - Basic predictive analytics

**Files to Modify**:
- `mcp_rag_playground/api/dashboard.py` - Add advanced analytics endpoints
- `static/dashboard.html` - Add advanced visualization components
- `mcp_rag_playground/container/container.py` - Register new analytics services

**Test Files to Create**:
- `mcp_rag_playground/tests/test_pattern_analyzer.py` - Query pattern analysis testing
- `mcp_rag_playground/tests/test_gap_detector.py` - Knowledge gap detection testing
- `mcp_rag_playground/tests/test_content_analyzer.py` - Content analysis testing
- `mcp_rag_playground/tests/test_advanced_dashboard.py` - Advanced dashboard testing

### Testing Requirements

**Test Requirements for This Story**:
- Unit tests for advanced analytics algorithms (marker: unit)
- Integration tests with historical analytics data (marker: integration)
- Performance tests for complex analysis operations (marker: performance)
- Export functionality testing with different formats
- Advanced dashboard feature testing

**Advanced Analytics Testing Pattern** (Required Implementation):
```python
def test_query_pattern_analysis():
    """Test query pattern analysis with sample data"""
    sample_queries = [
        "How do I configure the database?",
        "What is the API rate limit?", 
        "Install the dependencies",
        "Debug the connection error"
    ]
    
    analyzer = QueryPatternAnalyzer(mock_analytics_service)
    patterns = analyzer.analyze_query_patterns(30)
    
    assert 'question_queries' in patterns
    assert 'command_queries' in patterns
    assert len(patterns['question_queries']) >= 2  # "How" and "What" questions
    
def test_knowledge_gap_detection():
    """Test knowledge gap detection with failed queries"""
    failed_queries = [
        {'query_text': 'setup kubernetes cluster', 'result_count': 0, 'frequency': 5},
        {'query_text': 'docker compose configuration', 'result_count': 0, 'frequency': 3}
    ]
    
    detector = KnowledgeGapDetector(mock_analytics_service)
    gaps = detector.detect_knowledge_gaps(30)
    
    assert 'zero_result_queries' in gaps
    assert 'missing_content_suggestions' in gaps
    assert 'kubernetes' in gaps['missing_content_suggestions']
```

### Technical Constraints

**Performance Requirements**:
- Advanced analytics calculations must complete within 10 seconds for 30-day analysis
- Pattern analysis should be cached and refreshed hourly
- Export functionality must handle large datasets efficiently
- Dashboard loading must not be impacted by advanced analytics availability

**Optional Feature Status** [Source: Epic 2]:
- This story is marked as optional and can be deferred if Epic 2 timeline is constrained
- Core business value is delivered by Stories 2.1-2.4
- Advanced analytics provide additional strategic insights but are not required for basic KB health monitoring

### Architecture Integration

**SOLID Principles Compliance**:
- Single Responsibility: Each analyzer class focuses on specific analytics domain
- Open/Closed: Analytics framework can be extended with new analysis types
- Dependency Inversion: Analyzers depend on analytics service abstraction

**Existing Integration Points**:
- **Stories 2.1-2.4**: Uses complete analytics infrastructure for data access
- **Container DI**: Follows existing dependency injection patterns
- **Dashboard Framework**: Extends existing visualization components
- **API Patterns**: Maintains consistency with established endpoint conventions

## Testing

**Test File Location**: `mcp_rag_playground/tests/` following existing pattern

**Test Standards**:
- Use pytest framework with existing fixtures and patterns
- Follow existing marker system, add 'advanced' marker for advanced analytics tests
- Achieve 80% minimum code coverage for advanced analytics components
- Test with realistic data volumes and edge cases

**Testing Frameworks and Patterns**:
- Pytest with comprehensive analytics data fixtures
- Mock analytics service for unit tests
- Performance testing for complex analysis algorithms
- Integration testing with full analytics pipeline

**Specific Testing Requirements**:
- Advanced analytics algorithms: Test mathematical correctness and edge cases
- Pattern analysis: Test with various query types and volumes
- Knowledge gap detection: Test with known problematic scenarios
- Export functionality: Test data integrity and format validation
- Dashboard extensions: Test advanced visualization components and interactions

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|-----------|
| 2025-08-16 | 1.0 | Initial story creation for advanced analytics and monitoring | PM John |

## Dev Agent Record
*This section will be populated by the development agent during implementation*

### Agent Model Used

### Debug Log References

### Completion Notes List

### File List

## QA Results
*This section will be populated by the QA agent after story completion*