# Story 2.3: Dashboard Backend API

## Status
Draft

## Story
**As a** dashboard developer,  
**I want** RESTful APIs for analytics data and KPI monitoring,  
**so that** I can build responsive interfaces for KB health visualization and alerting.

## Acceptance Criteria
1. **FastAPI Endpoints**: Create REST API endpoints that expose analytics data and KPI calculations
2. **Real-time KPIs**: Provide endpoints for primary KPIs with configurable time windows
3. **Trend Analysis**: Implement endpoints for query trends, performance analytics, and usage patterns
4. **Alert System**: Create alert endpoints that detect KPI threshold violations and system issues
5. **REST API Integration**: Extend existing Story 1.6 REST API infrastructure with dashboard routes
6. **Performance Optimization**: API endpoints must respond within 500ms for dashboard real-time updates

## Tasks / Subtasks
- [ ] Create dashboard API router and endpoints (AC: 1, 5)
  - [ ] Create `mcp_rag_playground/api/dashboard.py` with FastAPI router
  - [ ] Implement dashboard router with prefix `/dashboard` and appropriate tags
  - [ ] Create static HTML endpoint `/dashboard/` serving dashboard interface
  - [ ] Integrate dashboard router with existing FastAPI app from Story 1.6
  - [ ] Add proper CORS configuration for dashboard web interface
- [ ] Implement KPI endpoints (AC: 2)
  - [ ] Create `GET /dashboard/api/kpis` endpoint with configurable time window parameter
  - [ ] Return primary KPIs: user satisfaction rate, query success rate, avg response time, source diversity index
  - [ ] Add KPI trend calculation with percentage change indicators
  - [ ] Implement KPI caching for improved response times
  - [ ] Add timestamp metadata for KPI freshness tracking
- [ ] Create analytics trend endpoints (AC: 3)
  - [ ] Implement `GET /dashboard/api/query-trends` endpoint with configurable date range
  - [ ] Return query volume, success rates, and response time trends over time
  - [ ] Create `GET /dashboard/api/top-queries` endpoint for most frequent queries analysis
  - [ ] Add query performance analytics with success rate and response time breakdown
  - [ ] Implement document utilization endpoints for content usage insights
- [ ] Build alert system API (AC: 4)
  - [ ] Create `GET /dashboard/api/alerts` endpoint for KPI violation detection
  - [ ] Implement configurable alert thresholds for each primary KPI
  - [ ] Add alert severity levels (info, warning, critical) based on threshold violations
  - [ ] Create alert history tracking and resolution status
  - [ ] Add alert acknowledgment endpoints for administrative management
- [ ] Optimize API performance (AC: 6)
  - [ ] Implement database query optimization for analytics data retrieval
  - [ ] Add response caching for frequently requested endpoints
  - [ ] Create efficient SQL queries with proper indexing for time-based analytics
  - [ ] Add response compression for large data sets
  - [ ] Implement pagination for endpoints returning large result sets
- [ ] Error handling and validation (AC: 1-6)
  - [ ] Add comprehensive request validation for all endpoint parameters
  - [ ] Implement proper HTTP status codes and error response formats
  - [ ] Add rate limiting to prevent API abuse
  - [ ] Create health check endpoint for API availability monitoring
  - [ ] Add logging for API performance and error tracking
- [ ] Unit testing for dashboard APIs (AC: 1-6)
  - [ ] Test all dashboard endpoints with FastAPI TestClient
  - [ ] Test KPI calculation accuracy with known data sets
  - [ ] Test trend analysis endpoints with time range variations
  - [ ] Test alert system with threshold violation scenarios
  - [ ] Test API performance and response time requirements
  - [ ] Test error handling and validation for invalid requests

## Dev Notes

### Previous Story Insights
This story builds upon Story 2.1 (Analytics Infrastructure) for data access and Story 1.6 (REST API Interface) for FastAPI foundation. The analytics service provides KPI calculation methods and data access that this story will expose through REST endpoints. Integration with existing FastAPI infrastructure ensures consistent API patterns.

### Dependencies
- **Story 2.1**: Analytics service for KPI calculations and data access
- **Epic 1 Story 1.6**: FastAPI application foundation and REST API patterns
- **SQLite Analytics Database**: Data source for all dashboard endpoints

### API Specifications

**Dashboard Router Integration** [Source: Story 1.6 REST API]:
```python
# Integration with existing FastAPI app
from fastapi import FastAPI
from mcp_rag_playground.api.dashboard import dashboard_router

app = FastAPI(title="RAG Knowledge Base API", version="1.0")
app.include_router(dashboard_router)
```

**KPI Endpoints** (Required Implementation):
```python
@dashboard_router.get("/api/kpis")
async def get_kpis(hours: int = 24) -> Dict:
    """Get primary KPIs for dashboard with configurable time window"""
    kpis = analytics_service.calculate_kpis(hours)
    return {
        "user_satisfaction_rate": kpis["user_satisfaction_rate"],
        "query_success_rate": kpis["query_success_rate"], 
        "avg_response_time": kpis["avg_response_time"],
        "source_diversity_index": kpis["source_diversity_index"],
        "timestamp": kpis["timestamp"],
        "time_window_hours": hours,
        "data_freshness": "real-time"
    }

@dashboard_router.get("/api/query-trends")
async def get_query_trends(days: int = 7) -> Dict:
    """Get query volume and success trends over time"""
    return {
        "dates": [...],
        "query_volumes": [...],
        "success_rates": [...],
        "response_times": [...]
    }

@dashboard_router.get("/api/top-queries")
async def get_top_queries(limit: int = 10) -> List[Dict]:
    """Get most frequent queries and their performance metrics"""
    return [
        {
            "query": "...",
            "frequency": 42,
            "avg_results": 3.2,
            "avg_rating": 4.1,
            "avg_response_time": 1.25
        }
    ]

@dashboard_router.get("/api/alerts")
async def get_alerts() -> List[Dict]:
    """Check for KPI violations and generate alerts"""
    return [
        {
            "level": "warning",
            "message": "User satisfaction below threshold: 72%",
            "metric": "satisfaction_rate",
            "current_value": 72.0,
            "threshold": 75.0,
            "timestamp": "2025-08-16T10:30:00Z"
        }
    ]
```

**Response Models** (Required Implementation):
```python
from pydantic import BaseModel
from typing import List, Optional
from datetime import datetime

class KPIResponse(BaseModel):
    user_satisfaction_rate: float
    query_success_rate: float
    avg_response_time: float
    source_diversity_index: float
    timestamp: datetime
    time_window_hours: int
    data_freshness: str

class QueryTrendResponse(BaseModel):
    dates: List[str]
    query_volumes: List[int]
    success_rates: List[float]
    response_times: List[float]

class TopQueryResponse(BaseModel):
    query: str
    frequency: int
    avg_results: float
    avg_rating: Optional[float]
    avg_response_time: float

class AlertResponse(BaseModel):
    level: str  # info, warning, critical
    message: str
    metric: str
    current_value: float
    threshold: float
    timestamp: datetime
```

### Component Specifications

**Analytics Service Integration** [Source: Story 2.1]:
Dashboard APIs must access analytics service through existing container DI:
```python
from mcp_rag_playground.container.container import Container

container = Container()
analytics_service = container.analytics_service()
```

**Database Query Optimization** [Required Implementation]:
APIs must implement efficient SQLite queries for real-time dashboard performance:
- Use proper indexes on timestamp and metric fields
- Implement query result caching for frequently accessed data
- Add query pagination for large result sets
- Optimize aggregation queries for KPI calculations

**Alert Threshold Configuration** [Source: Story 2.1 AnalyticsConfig]:
```python
alert_thresholds = {
    'satisfaction_rate': 75,      # Below 75% triggers warning
    'success_rate': 85,           # Below 85% triggers critical
    'response_time': 3.0,         # Above 3s triggers warning
    'diversity_index': 0.5        # Below 0.5 triggers info
}
```

### File Locations

**Files to Create**:
- `mcp_rag_playground/api/dashboard.py` - Dashboard API router and endpoints
- `mcp_rag_playground/api/models/dashboard_models.py` - Dashboard response models
- `static/dashboard.html` - Dashboard HTML interface (basic structure)

**Files to Modify**:
- `mcp_rag_playground/api/rest_server.py` - Include dashboard router (if exists from Story 1.6)
- `mcp_rag_playground/container/container.py` - Add dashboard service registration if needed

**Test Files to Create**:
- `mcp_rag_playground/tests/test_dashboard_api.py` - Dashboard API endpoint testing
- `mcp_rag_playground/tests/test_dashboard_integration.py` - API integration with analytics service

### Testing Requirements

**Current Test Structure** [Source: docs/architecture/testing-reality.md]:
- Framework: pytest with FastAPI TestClient for HTTP endpoint testing
- Coverage target: 80% minimum  
- Test files use `test_*.py` naming convention
- API testing requires TestClient and async test support

**Test Requirements for This Story**:
- Unit tests for dashboard API endpoints (marker: unit, api)
- Integration tests with analytics service (marker: integration)
- Performance tests for API response times (marker: performance)
- Error handling and validation tests
- Alert system functionality tests

**API Testing Pattern** [Required Implementation]:
```python
from fastapi.testclient import TestClient
from mcp_rag_playground.api.rest_server import app

client = TestClient(app)

def test_get_kpis():
    """Test KPI endpoint returns valid data"""
    response = client.get("/dashboard/api/kpis?hours=24")
    assert response.status_code == 200
    
    data = response.json()
    assert "user_satisfaction_rate" in data
    assert "query_success_rate" in data
    assert "avg_response_time" in data
    assert "source_diversity_index" in data
    assert data["time_window_hours"] == 24

def test_query_trends():
    """Test query trends endpoint"""
    response = client.get("/dashboard/api/query-trends?days=7")
    assert response.status_code == 200
    
    data = response.json()
    assert "dates" in data
    assert "query_volumes" in data
    assert len(data["dates"]) == len(data["query_volumes"])

def test_alerts():
    """Test alert detection endpoint"""
    response = client.get("/dashboard/api/alerts")
    assert response.status_code == 200
    
    alerts = response.json()
    assert isinstance(alerts, list)
    for alert in alerts:
        assert "level" in alert
        assert alert["level"] in ["info", "warning", "critical"]
```

### Technical Constraints

**Performance Requirements** [Source: AC 6]:
- API endpoints must respond within 500ms for real-time dashboard updates
- Database queries must be optimized with proper indexing
- Response caching should be implemented for frequently accessed data
- Large result sets must use pagination to maintain performance

**Integration Requirements** [Source: AC 5]:
- Must extend existing Story 1.6 REST API infrastructure
- Follow established FastAPI patterns and conventions
- Maintain consistency with existing API response formats
- Use existing CORS and middleware configurations

**Data Accuracy Requirements**:
- KPI calculations must be mathematically correct and testable
- Time window parameters must be validated and applied correctly
- Alert thresholds must be configurable and accurately enforced
- Trend data must reflect actual analytics database content

### Architecture Integration

**SOLID Principles Compliance**:
- Single Responsibility: Dashboard APIs focus solely on data exposure for visualization
- Open/Closed: Extends existing FastAPI infrastructure without modification
- Dependency Inversion: Depends on analytics service abstraction through container DI

**Existing Integration Points**:
- **Story 2.1**: Uses analytics service for data access and KPI calculations
- **Story 1.6**: Extends existing FastAPI application and router patterns
- **Container DI**: Leverages existing dependency injection for service access
- **Configuration System**: Uses existing pydantic-based configuration approach

## Testing

**Test File Location**: `mcp_rag_playground/tests/` following existing pattern

**Test Standards**:
- Use pytest framework with FastAPI TestClient for HTTP testing
- Follow existing marker system, add 'api' and 'dashboard' markers
- Achieve 80% minimum code coverage for dashboard API components
- Test both successful responses and error scenarios
- Mock analytics service for unit tests, use real service for integration tests

**Testing Frameworks and Patterns**:
- FastAPI TestClient for HTTP endpoint testing
- pytest-asyncio for async endpoint testing
- Response validation against pydantic models
- Performance benchmarking for response time requirements

**Specific Testing Requirements**:
- API endpoint functionality: Test all HTTP methods and status codes
- KPI calculation accuracy: Verify mathematical correctness with known data
- Trend analysis: Test time window parameters and data aggregation
- Alert system: Test threshold detection and alert generation
- Performance validation: Benchmark response times under typical load
- Error handling: Test invalid parameters and service unavailability scenarios

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|-----------|
| 2025-08-16 | 1.0 | Initial story creation for dashboard backend API | PM John |

## Dev Agent Record
*This section will be populated by the development agent during implementation*

### Agent Model Used

### Debug Log References

### Completion Notes List

### File List

## QA Results
*This section will be populated by the QA agent after story completion*