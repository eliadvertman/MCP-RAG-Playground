# Story 1.5: Add Async Document Processing Capabilities

**Story ID:** 1.5  
**Epic:** Critical Architecture Remediation - Foundation (Epic 1)  
**Status:** Draft  
**Priority:** Medium  
**Story Points:** 8  

## Story Statement

**As a** system processing large documents or multiple files  
**I want** asynchronous document processing capabilities  
**So that** I can handle large document ingestion without blocking other operations and improve overall throughput  

## Background Context

This is a **brownfield scalability enhancement story** that addresses performance bottlenecks in the existing MCP RAG Playground system. Currently, all document processing is synchronous, limiting throughput and causing blocking behavior during large file processing.

**Current State:**
- Synchronous document processing in `VectorClient.upload()`
- Sequential chunking and embedding operations block the main thread
- Large files cause system unresponsiveness during processing
- No support for concurrent document ingestion

**Business Impact:**
- 5x throughput improvement potential for large document processing
- Better user experience with non-blocking operations
- Foundation for batch processing and parallel ingestion workflows

## Acceptance Criteria

1. **Async Method Variants**: Add async versions of document processing methods
2. **Backward Compatibility**: Existing synchronous methods continue working unchanged
3. **Async Pipeline**: Implement async document processing pipeline (file → chunks → embeddings → storage)
4. **Progress Tracking**: Provide progress updates for long-running async operations
5. **Error Handling**: Robust error handling for async operations with proper cleanup
6. **Resource Management**: Prevent resource exhaustion through concurrent operation limits
7. **Integration**: Async methods work with existing DI container and factory patterns

## Dev Notes

### **Previous Story Context**
**Dependencies:**
- Story 1.1 (Import Chain Fix) - Required for module exports
- Story 1.2 (Factory Methods) - Async methods available through factories
- Story 1.3 (Health Checks) - Async operation monitoring
- Story 1.4 (Connection Pooling) - Async operations use connection pool

### **Current Architecture Analysis**
**Source: [vector_client.py, rag_api.py, document_processor.py]**

**Current Synchronous Processing Pipeline:**
```python
# VectorClient.upload() - Lines 50-89
def upload(self, file_path: str) -> bool:
    documents = self.document_processor.process_file(file_path)  # Blocking
    texts = [doc.content for doc in documents]
    embeddings = self.embedding_service.embed_texts(texts)      # Blocking
    success = self.vector_db.insert_documents(...)              # Blocking
```

**Processing Bottlenecks:**
1. **File Processing**: Large files processed entirely in memory
2. **Embedding Generation**: Batch embedding operations block execution
3. **Vector Storage**: Sequential document insertion to Milvus
4. **No Concurrency**: Single-threaded processing limits throughput

**Current Components:**
- `DocumentProcessor.process_file()` - Synchronous file processing
- `SentenceTransformerEmbedding.embed_texts()` - Batch embedding generation
- `MilvusVectorDB.insert_documents()` - Batch vector insertion

### **Technical Implementation Strategy**
**Source: [architecture-analysis.md - Async Processing Layer]**

**Async Enhancement Pattern:**
```python
# Existing sync methods preserved, async variants added
class VectorClient:
    def upload(self, file_path: str) -> bool:      # Existing - unchanged
        return self._sync_upload_implementation()
    
    async def upload_async(self, file_path: str) -> bool:  # New - additive
        return await self._async_upload_implementation()
```

**Async Pipeline Architecture:**
```
File Input → Async Document Processing → Async Chunking → 
Async Embedding Batches → Async Vector Storage → Progress Updates
```

### **File Locations**
**Source: [vector_client.py, rag_api.py, document_processor.py locations]**

**Files to Modify (Additive Changes):**
- `mcp_rag_playground/vectordb/vector_client.py` - Add async upload methods
- `mcp_rag_playground/rag/rag_api.py` - Add async document addition
- `mcp_rag_playground/vectordb/processor/document_processor.py` - Add async processing
- `mcp_rag_playground/vectordb/embedding_service.py` - Add async embedding methods

**New Files to Create:**
- `mcp_rag_playground/vectordb/async_utils.py` - Async utilities and progress tracking
- `mcp_rag_playground/vectordb/batch_processor.py` - Async batch processing coordination

### **Async Processing Components**
**Source: [python asyncio patterns, async file processing]**

**Async Processing Stages:**

1. **Async File Reading**: Stream large files without blocking
2. **Async Chunking**: Process documents in chunks to prevent memory issues
3. **Async Embedding**: Batch embeddings with configurable concurrency
4. **Async Storage**: Non-blocking vector database operations
5. **Progress Tracking**: Real-time progress updates for long operations

**Concurrency Controls:**
- Semaphore-based limiting for embedding operations
- Queue-based processing for document batches
- Memory-aware chunking to prevent resource exhaustion

### **Integration with Existing Components**
**Source: [container/container.py, factories patterns]**

**Container Integration:**
- Async methods use same DI-managed components
- Connection pool enables concurrent database operations
- Factory methods provide async-capable components

**MCP Server Integration:**
- Async methods compatible with FastMCP async patterns
- Progress tracking through MCP tool responses
- Background processing with status reporting

### **Configuration Requirements**
**Source: [async processing best practices, resource management]**

**New Configuration Parameters:**
```python
# Addition to configuration
max_concurrent_embeddings: int = 5    # Concurrent embedding operations
async_batch_size: int = 100          # Documents per async batch
async_chunk_size: int = 10           # Files per processing chunk  
progress_update_interval: int = 10    # Progress update frequency
async_timeout: int = 300             # Async operation timeout (seconds)
```

**Environment Variables:**
- `ASYNC_MAX_CONCURRENT_EMBEDDINGS`
- `ASYNC_BATCH_SIZE`
- `ASYNC_CHUNK_SIZE`
- `ASYNC_PROGRESS_INTERVAL`
- `ASYNC_OPERATION_TIMEOUT`

### **Progress Tracking Design**
**Source: [async progress patterns, callback mechanisms]**

**Progress Callback Interface:**
```python
from typing import Callable, Optional
from dataclasses import dataclass

@dataclass
class ProcessingProgress:
    total_documents: int
    processed_documents: int
    current_stage: str
    estimated_remaining: Optional[float]

ProgressCallback = Callable[[ProcessingProgress], None]
```

### **Error Handling Strategy**
**Source: [async error handling best practices]**

**Async Error Scenarios:**
- File reading errors during streaming
- Embedding service failures during batch processing
- Vector database connection issues during storage
- Memory exhaustion during large file processing
- Timeout errors for long-running operations

**Recovery Patterns:**
- Partial failure handling with completed document tracking
- Automatic retry for transient failures
- Graceful degradation to synchronous processing
- Resource cleanup on operation cancellation

## Tasks / Subtasks

### **Task 1: Design Async Processing Architecture** (AC: 3, 5)
- Design async processing pipeline stages
- Plan progress tracking and callback mechanisms
- Define error handling and recovery patterns
- **Reference:** [Source: vector_client.py - current processing flow]

### **Task 2: Implement Async Document Processing** (AC: 1, 3)
- Add async methods to `DocumentProcessor` class
- Implement streaming file processing for large files
- Add memory-aware chunking to prevent resource exhaustion
- **Reference:** [Source: document_processor.py - process_file method]

### **Task 3: Add Async Embedding Generation** (AC: 1, 3)
- Extend `SentenceTransformerEmbedding` with async methods
- Implement concurrent embedding with semaphore limiting
- Add batch processing for efficient embedding generation
- **Reference:** [Source: embedding_service.py - embed_texts method]

### **Task 4: Implement Async Vector Storage** (AC: 1, 3)
- Add async methods to `MilvusVectorDB` class
- Implement non-blocking vector insertion using connection pool
- Add concurrent document insertion with batching
- **Reference:** [Source: milvus_client.py - insert_documents method]

### **Task 5: Create Async VectorClient Methods** (AC: 1, 2, 4)
- Add `upload_async()` method to `VectorClient`
- Implement async processing pipeline coordination
- Add progress tracking with callback support
- Maintain existing synchronous API unchanged
- **Reference:** [Source: vector_client.py - upload method]

### **Task 6: Add Async RAG API Methods** (AC: 1, 2, 4)
- Extend `RagAPI` with `add_document_async()` method
- Implement async query processing capabilities
- Add progress tracking for multi-document operations
- **Reference:** [Source: rag_api.py - add_document method]

### **Task 7: Implement Progress Tracking System** (AC: 4)
- Create progress tracking utilities in `async_utils.py`
- Implement callback-based progress reporting
- Add estimated time remaining calculations
- **Reference:** [Source: async progress tracking patterns]

### **Task 8: Add Resource Management Controls** (AC: 6)
- Implement concurrency limiting with semaphores
- Add memory usage monitoring during processing
- Implement automatic garbage collection for large operations
- **Reference:** [Source: async resource management patterns]

### **Task 9: Create Async Error Handling** (AC: 5)
- Implement comprehensive async error handling
- Add automatic retry for transient failures
- Create cleanup mechanisms for failed operations
- Add timeout handling for long-running operations
- **Reference:** [Source: async error handling best practices]

### **Task 10: Update Factory Methods for Async Support** (AC: 7)
- Update factory methods to create async-capable components
- Add factory methods specifically for async workflows
- Maintain backward compatibility with existing factories
- **Reference:** [Source: Story 1.2 - factory method patterns]

### **Task 11: Integrate with MCP Server** (AC: 1, 4)
- Add async MCP tools for document processing
- Implement progress reporting through MCP responses
- Add background task management for async operations
- **Reference:** [Source: mcp/rag_server.py - tool patterns]

### **Task 12: Create Comprehensive Async Tests** (AC: 1-7)
- Test async methods with various file sizes
- Test concurrent operation limits and resource management
- Test progress tracking and error handling scenarios
- Test integration with connection pool and existing components
- **Reference:** [Source: CLAUDE.md - testing patterns]

## Definition of Done

- [ ] Async variants added for all document processing methods
- [ ] Existing synchronous methods work unchanged (backward compatibility)
- [ ] Async processing pipeline handles large files without memory issues
- [ ] Progress tracking implemented with callback support
- [ ] Robust error handling with automatic retry and cleanup
- [ ] Resource management prevents system exhaustion under load
- [ ] Async methods integrate with existing DI container and factories
- [ ] MCP server tools support async operations with progress reporting
- [ ] Comprehensive test suite covering async scenarios and edge cases
- [ ] Performance improvement measurable (5x throughput for large files)
- [ ] Configuration support for async operation parameters
- [ ] Documentation updated with async API usage examples

## Notes

**Brownfield Considerations:**
- All existing synchronous APIs must remain unchanged
- Async methods should be additive enhancements only
- Must work with existing component architecture
- No changes to core component initialization patterns

**Performance Expectations:**
- 5x throughput improvement for large document processing
- Non-blocking behavior during file ingestion
- Efficient resource utilization through concurrent operations
- Scalable to handle multiple simultaneous uploads

**Resource Management:**
- Memory usage should remain bounded regardless of file size
- Concurrent operations should not exhaust system resources
- Proper cleanup of resources on operation failure or cancellation
- Configurable limits to prevent system overload

**Risk Mitigation:**
- Extensive testing with large files and concurrent operations
- Fallback to synchronous processing if async operations fail
- Memory leak testing for long-running async operations
- Test timeout scenarios and resource cleanup
- Verify backward compatibility through comprehensive regression testing

---

**Story Created:** 2025-08-10  
**Source Requirements:** Project Brief MVP Scope - Async Document Processing  
**Architecture Context:** vector_client.py processing pipeline, scalability requirements  
**Dependencies:** Story 1.1-1.4 (Foundation components)